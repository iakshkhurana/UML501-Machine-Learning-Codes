{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f31013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60539b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (500, 8)\n",
      "Correlation matrix (first 3x3):\n",
      "[[1.         0.997093   0.99704355]\n",
      " [0.997093   1.         0.99719576]\n",
      " [0.99704355 0.99719576 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "n, p = 500, 8  # 500 samples, 8 features (>=7 highly correlated)\n",
    "\n",
    "# Create latent factor for high correlation\n",
    "z = rng.normal(0, 1, size=(n, 1))\n",
    "X = np.hstack([z + rng.normal(0, 0.05, size=(n, 1)) for _ in range(p)])  # Strong correlation\n",
    "true_w = rng.normal(0, 1, size=(p, 1))\n",
    "y = (X @ true_w + rng.normal(0, 0.2, size=(n, 1))).ravel()\n",
    "\n",
    "# Standardize features (important for gradient descent)\n",
    "X_mean, X_std = X.mean(axis=0), X.std(axis=0) + 1e-12\n",
    "X = (X - X_mean) / X_std\n",
    "\n",
    "# Center target variable\n",
    "y_mean = y.mean()\n",
    "y = y - y_mean\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Correlation matrix (first 3x3):\")\n",
    "print(np.corrcoef(X[:, :3].T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b6b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Ridge Regression with Gradient Descent\n",
    "\n",
    "def ridge_cost(X, y, w, b, alpha):\n",
    "    \"\"\"Calculate Ridge regression cost (MSE + L2 regularization)\"\"\"\n",
    "    n = len(y)\n",
    "    pred = X @ w + b\n",
    "    mse_term = np.mean((y - pred) ** 2)\n",
    "    reg_term = alpha * np.sum(w ** 2) \n",
    "    return mse_term + reg_term\n",
    "\n",
    "def r2_score(y, yhat):\n",
    "    \"\"\"Calculate R¬≤ score\"\"\"\n",
    "    ss_res = np.sum((y - yhat) ** 2)\n",
    "    ss_tot = np.sum((y - y.mean()) ** 2) + 1e-12\n",
    "    return 1.0 - ss_res / ss_tot\n",
    "\n",
    "def ridge_gd(X, y, alpha=0.0, lr=1e-2, max_iter=5000, tol=1e-8):\n",
    "    \"\"\"Ridge regression using gradient descent\"\"\"\n",
    "    n, p = X.shape\n",
    "    w = np.zeros((p,))\n",
    "    b = 0.0\n",
    "    prev_cost = np.inf\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        pred = X @ w + b\n",
    "        resid = y - pred\n",
    "        \n",
    "        grad_w = (-2.0 / n) * (X.T @ resid) + 2.0 * alpha * w\n",
    "        grad_b = (-2.0 / n) * resid.sum()\n",
    "        \n",
    "        w -= lr * grad_w\n",
    "        b -= lr * grad_b\n",
    "        \n",
    "        cost = ridge_cost(X, y, w, b, alpha)\n",
    "        if not np.isfinite(cost) or cost > 1e8:  \n",
    "            return None, None, np.inf, -np.inf\n",
    "        if abs(prev_cost - cost) < tol:\n",
    "            break\n",
    "        prev_cost = cost\n",
    "    \n",
    "    return w, b, cost, r2_score(y, X @ w + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbd57d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 settings (by cost, tie-broken by R¬≤):\n",
      "cost=0.040399 | R¬≤=0.6724 | lr=0.1 | alpha=0.0\n",
      "cost=0.040399 | R¬≤=0.6724 | lr=0.1 | alpha=1e-15\n",
      "cost=0.040399 | R¬≤=0.6724 | lr=0.1 | alpha=1e-10\n",
      "cost=0.040479 | R¬≤=0.6723 | lr=0.1 | alpha=1e-05\n",
      "cost=0.046116 | R¬≤=0.6566 | lr=0.1 | alpha=0.001\n",
      "\n",
      "Best parameters:\n",
      "  Learning rate (lr): 0.1\n",
      "  Regularization (alpha): 0.0\n",
      "Best Ridge Cost: 0.040399\n",
      "Best R¬≤ Score:  0.672416\n",
      "\n",
      "Weights (first 5): [-1.2584  0.7628 -1.1189  0.6002 -0.6045] ...  Bias: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 3) Hyperparameter Grid Search\n",
    "\n",
    "learning_rates = [1e-4, 1e-3, 1e-2, 0.1, 1.0, 10.0]\n",
    "alphas = [1e-15, 1e-10, 1e-5, 1e-3, 0.0, 1.0, 10.0, 20.0]\n",
    "\n",
    "results = []\n",
    "for lr in learning_rates:\n",
    "    for alpha in alphas:\n",
    "        w, b, cost, r2 = ridge_gd(X, y, alpha=alpha, lr=lr, max_iter=5000)\n",
    "        results.append((cost, -r2, lr, alpha, r2))\n",
    "\n",
    "results.sort(key=lambda t: (t[0], t[1]))\n",
    "best_cost, _, best_lr, best_alpha, best_r2 = results[0]\n",
    "\n",
    "print(\"Top 5 settings (by cost, tie-broken by R¬≤):\")\n",
    "for row in results[:5]:\n",
    "    print(f\"cost={row[0]:.6f} | R¬≤={-row[1]:.4f} | lr={row[2]} | alpha={row[3]}\")\n",
    "\n",
    "print(\"\\nBest parameters:\")\n",
    "print(f\"  Learning rate (lr): {best_lr}\")\n",
    "print(f\"  Regularization (alpha): {best_alpha}\")\n",
    "print(f\"Best Ridge Cost: {best_cost:.6f}\")\n",
    "print(f\"Best R¬≤ Score:  {best_r2:.6f}\")\n",
    "\n",
    "w_best, b_best, _, _ = ridge_gd(X, y, alpha=best_alpha, lr=best_lr, max_iter=5000)\n",
    "print(\"\\nWeights (first 5):\", np.round(w_best[:5], 4), \"...  Bias:\", round(b_best, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0f2d5",
   "metadata": {},
   "source": [
    "Question - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df08613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d32b87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (322, 20)\n",
      "Missing values per column:\n",
      " AtBat         0\n",
      "Hits          0\n",
      "HmRun         0\n",
      "Runs          0\n",
      "RBI           0\n",
      "Walks         0\n",
      "Years         0\n",
      "CAtBat        0\n",
      "CHits         0\n",
      "CHmRun        0\n",
      "CRuns         0\n",
      "CRBI          0\n",
      "CWalks        0\n",
      "League        0\n",
      "Division      0\n",
      "PutOuts       0\n",
      "Assists       0\n",
      "Errors        0\n",
      "Salary       59\n",
      "NewLeague     0\n",
      "dtype: int64\n",
      "\n",
      "After preprocessing - Shape: (263, 20)\n",
      "Missing values after preprocessing:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# url = \"https://drive.google.com/uc?id=1qzCKF6JKKMB0p7ul_lLy8tdmRk3vE_bG\"\n",
    "file_path = \"Hitters.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Initial shape:\", df.shape)\n",
    "print(\"Missing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Drop rows with null target (Salary)\n",
    "df = df.dropna(subset=['Salary'])\n",
    "\n",
    "# Fill other missing values with mode (categorical) or mean (numeric)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "# Convert categoricals to numeric using one-hot encoding\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "print(f\"\\nAfter preprocessing - Shape: {df.shape}\")\n",
    "print(\"Missing values after preprocessing:\\n\", df.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83505dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (263, 19)\n",
      "Target shape: (263,)\n",
      "\n",
      "Train set: (210, 19)\n",
      "Test set: (53, 19)\n",
      "Target statistics - Mean: 535.93, Std: 451.12\n"
     ]
    }
   ],
   "source": [
    "# Separate input and output features\n",
    "X = df.drop('Salary', axis=1)\n",
    "y = df['Salary']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (important for regularization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTrain set: {X_train_scaled.shape}\")\n",
    "print(f\"Test set: {X_test_scaled.shape}\")\n",
    "print(f\"Target statistics - Mean: {y.mean():.2f}, Std: {y.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a00a896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating models...\n",
      "--------------------------------------------------\n",
      "Linear Regression:\n",
      "  R¬≤ Score: 0.2907\n",
      "  MSE: 128284.35\n",
      "\n",
      "Ridge Regression:\n",
      "  R¬≤ Score: 0.3000\n",
      "  MSE: 126603.90\n",
      "\n",
      "Lasso Regression:\n",
      "  R¬≤ Score: 0.2993\n",
      "  MSE: 126739.57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akshk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.185e+04, tolerance: 4.367e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Set regularization parameter as specified (0.5748)\n",
    "alpha = 0.5748\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=alpha),\n",
    "    'Lasso Regression': Lasso(alpha=alpha)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "print(\"Training and evaluating models...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {'R2': r2, 'MSE': mse}\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  R¬≤ Score: {r2:.4f}\")\n",
    "    print(f\"  MSE: {mse:.2f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca9a65cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODEL COMPARISON RESULTS\n",
      "============================================================\n",
      "Model                R¬≤ Score   MSE       \n",
      "----------------------------------------\n",
      "Linear Regression    0.2907     128284.35 \n",
      "Ridge Regression     0.3000     126603.90 \n",
      "Lasso Regression     0.2993     126739.57 \n",
      "\n",
      "============================================================\n",
      "BEST MODEL: Ridge Regression\n",
      "R¬≤ Score: 0.3000\n",
      "MSE: 126603.90\n",
      "============================================================\n",
      "\n",
      "EXPLANATION:\n",
      "--------------------\n",
      "\n",
      "‚Ä¢ Linear Regression: \n",
      "  - No regularization, can overfit with correlated features\n",
      "  - High variance, may not generalize well\n",
      "\n",
      "‚Ä¢ Ridge Regression (L2): \n",
      "  - Shrinks coefficients towards zero but doesn't eliminate them\n",
      "  - Balances bias-variance tradeoff effectively\n",
      "  - Good for correlated features (like in Hitters dataset)\n",
      "\n",
      "‚Ä¢ Lasso Regression (L1): \n",
      "  - Can zero out coefficients (feature selection)\n",
      "  - May be too aggressive for this dataset\n",
      "  - Good when you want automatic feature selection\n",
      "\n",
      "Typically, Ridge performs best on highly correlated datasets\n",
      "because it handles multicollinearity well while maintaining\n",
      "all features with reduced coefficients.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the best performing model\n",
    "best_model = max(results.items(), key=lambda x: x[1]['R2'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display all results in a table format\n",
    "print(f\"{'Model':<20} {'R¬≤ Score':<10} {'MSE':<10}\")\n",
    "print(\"-\" * 40)\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name:<20} {metrics['R2']:<10.4f} {metrics['MSE']:<10.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"BEST MODEL: {best_model[0]}\")\n",
    "print(f\"R¬≤ Score: {best_model[1]['R2']:.4f}\")\n",
    "print(f\"MSE: {best_model[1]['MSE']:.2f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ------------------------------\n",
    "# Explanation of Results\n",
    "# ------------------------------\n",
    "print(\"\\nEXPLANATION:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"\"\"\n",
    "‚Ä¢ Linear Regression: \n",
    "  - No regularization, can overfit with correlated features\n",
    "  - High variance, may not generalize well\n",
    "\n",
    "‚Ä¢ Ridge Regression (L2): \n",
    "  - Shrinks coefficients towards zero but doesn't eliminate them\n",
    "  - Balances bias-variance tradeoff effectively\n",
    "  - Good for correlated features (like in Hitters dataset)\n",
    "\n",
    "‚Ä¢ Lasso Regression (L1): \n",
    "  - Can zero out coefficients (feature selection)\n",
    "  - May be too aggressive for this dataset\n",
    "  - Good when you want automatic feature selection\n",
    "\n",
    "Typically, Ridge performs best on highly correlated datasets\n",
    "because it handles multicollinearity well while maintaining\n",
    "all features with reduced coefficients.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8dd277",
   "metadata": {},
   "source": [
    "# Question 3: Cross Validation for Ridge and Lasso Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f5453d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Question 3: RidgeCV & LassoCV on Boston Housing\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2114d1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Boston dataset using fetch_openml\n",
      "Dataset shape: (506, 13)\n",
      "Target shape: (506,)\n",
      "Features: ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
      "Target statistics - Mean: 22.53, Std: 9.19\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Load Boston Housing Dataset\n",
    "# -----------------------------\n",
    "def load_boston_data():\n",
    "    \"\"\"Load Boston housing dataset with fallback for deprecated load_boston\"\"\"\n",
    "    try:\n",
    "        # Try the original load_boston (deprecated in newer sklearn)\n",
    "        from sklearn.datasets import load_boston\n",
    "        boston = load_boston()\n",
    "        X, y = boston.data, boston.target\n",
    "        feature_names = boston.feature_names\n",
    "        print(\"Loaded Boston dataset using load_boston\")\n",
    "    except Exception:\n",
    "        # Fallback to OpenML if load_boston is not available\n",
    "        from sklearn.datasets import fetch_openml\n",
    "        boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
    "        X = boston.data.values\n",
    "        y = boston.target.values.astype(float)\n",
    "        feature_names = boston.data.columns.values\n",
    "        print(\"Loaded Boston dataset using fetch_openml\")\n",
    "    \n",
    "    return X, y, feature_names\n",
    "\n",
    "# Load the dataset\n",
    "X, y, feature_names = load_boston_data()\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Features: {list(feature_names)}\")\n",
    "print(f\"Target statistics - Mean: {y.mean():.2f}, Std: {y.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "383c8bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (404, 13)\n",
      "Test set: (102, 13)\n",
      "Alpha range: 0.001 to 1000.000\n",
      "Number of alpha values: 50\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Train/Test Split and Alpha Grid\n",
    "# -----------------------------\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create alpha grid for cross-validation\n",
    "alphas = np.logspace(-3, 3, 50)  # 50 values from 0.001 to 1000\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"Alpha range: {alphas[0]:.3f} to {alphas[-1]:.3f}\")\n",
    "print(f\"Number of alpha values: {len(alphas)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31a569fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV Results:\n",
      "  Best alpha: 2.68270\n",
      "  R¬≤ Score: 0.6680\n",
      "  RMSE: 4.935\n",
      "  Cross-validation: 5-fold\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# RidgeCV Implementation\n",
    "# -----------------------------\n",
    "# Create RidgeCV pipeline with scaling\n",
    "ridge_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", RidgeCV(alphas=alphas, cv=5))\n",
    "])\n",
    "\n",
    "# Fit RidgeCV model\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ridge_pred = ridge_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "ridge_rmse = np.sqrt(ridge_mse)  # Calculate RMSE manually\n",
    "best_ridge_alpha = ridge_pipeline.named_steps[\"ridge\"].alpha_\n",
    "\n",
    "print(\"RidgeCV Results:\")\n",
    "print(f\"  Best alpha: {best_ridge_alpha:.5f}\")\n",
    "print(f\"  R¬≤ Score: {ridge_r2:.4f}\")\n",
    "print(f\"  RMSE: {ridge_rmse:.3f}\")\n",
    "print(f\"  Cross-validation: 5-fold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84c87279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV Results:\n",
      "  Best alpha: 0.00100\n",
      "  R¬≤ Score: 0.6687\n",
      "  RMSE: 4.929\n",
      "  Non-zero coefficients: 13/13\n",
      "  Cross-validation: 5-fold\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# LassoCV Implementation\n",
    "# -----------------------------\n",
    "# Create LassoCV pipeline with scaling\n",
    "lasso_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lasso\", LassoCV(alphas=alphas, cv=5, max_iter=20000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit LassoCV model\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lasso_pred = lasso_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "lasso_r2 = r2_score(y_test, lasso_pred)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "lasso_rmse = np.sqrt(lasso_mse)  # Calculate RMSE manually\n",
    "best_lasso_alpha = lasso_pipeline.named_steps[\"lasso\"].alpha_\n",
    "\n",
    "# Count non-zero coefficients (feature selection)\n",
    "lasso_coef = lasso_pipeline.named_steps[\"lasso\"].coef_\n",
    "nonzero_coef = np.count_nonzero(lasso_coef)\n",
    "total_features = lasso_coef.size\n",
    "\n",
    "print(\"LassoCV Results:\")\n",
    "print(f\"  Best alpha: {best_lasso_alpha:.5f}\")\n",
    "print(f\"  R¬≤ Score: {lasso_r2:.4f}\")\n",
    "print(f\"  RMSE: {lasso_rmse:.3f}\")\n",
    "print(f\"  Non-zero coefficients: {nonzero_coef}/{total_features}\")\n",
    "print(f\"  Cross-validation: 5-fold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05cdaa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RIDGE vs LASSO COMPARISON\n",
      "============================================================\n",
      "Metric               RidgeCV         LassoCV        \n",
      "--------------------------------------------------\n",
      "R¬≤ Score             0.6680          0.6687         \n",
      "RMSE                 4.935           4.929          \n",
      "Best Alpha           2.68270         0.00100        \n",
      "Features Used        All (13)        13/13          \n",
      "\n",
      "============================================================\n",
      "ANALYSIS:\n",
      "--------------------\n",
      "üèÜ LassoCV performs better:\n",
      "   ‚Ä¢ Higher R¬≤ score with feature selection\n",
      "   ‚Ä¢ Sparse model reduces overfitting\n",
      "   ‚Ä¢ Automatic feature selection helps generalization\n",
      "\n",
      "Key Insights:\n",
      "‚Ä¢ Ridge uses all 13 features with shrinkage\n",
      "‚Ä¢ Lasso uses only 13 features (automatic selection)\n",
      "‚Ä¢ Cross-validation ensures robust hyperparameter selection\n",
      "‚Ä¢ Both models benefit from proper feature scaling\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Model Comparison and Analysis\n",
    "# -----------------------------\n",
    "print(\"=\" * 60)\n",
    "print(\"RIDGE vs LASSO COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comparison table\n",
    "print(f\"{'Metric':<20} {'RidgeCV':<15} {'LassoCV':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'R¬≤ Score':<20} {ridge_r2:<15.4f} {lasso_r2:<15.4f}\")\n",
    "print(f\"{'RMSE':<20} {ridge_rmse:<15.3f} {lasso_rmse:<15.3f}\")\n",
    "print(f\"{'Best Alpha':<20} {best_ridge_alpha:<15.5f} {best_lasso_alpha:<15.5f}\")\n",
    "print(f\"{'Features Used':<20} {'All (13)':<15} {f'{nonzero_coef}/13':<15}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ANALYSIS:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "if ridge_r2 > lasso_r2:\n",
    "    print(\"üèÜ RidgeCV performs better:\")\n",
    "    print(\"   ‚Ä¢ Higher R¬≤ score indicates better fit\")\n",
    "    print(\"   ‚Ä¢ Ridge shrinks coefficients without eliminating features\")\n",
    "    print(\"   ‚Ä¢ Better for correlated features (common in housing data)\")\n",
    "elif lasso_r2 > ridge_r2:\n",
    "    print(\"üèÜ LassoCV performs better:\")\n",
    "    print(\"   ‚Ä¢ Higher R¬≤ score with feature selection\")\n",
    "    print(\"   ‚Ä¢ Sparse model reduces overfitting\")\n",
    "    print(\"   ‚Ä¢ Automatic feature selection helps generalization\")\n",
    "else:\n",
    "    print(\"ü§ù Both models perform similarly:\")\n",
    "    print(\"   ‚Ä¢ Similar R¬≤ scores and RMSE\")\n",
    "    print(\"   ‚Ä¢ Choice depends on interpretability vs sparsity needs\")\n",
    "\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"‚Ä¢ Ridge uses all {total_features} features with shrinkage\")\n",
    "print(f\"‚Ä¢ Lasso uses only {nonzero_coef} features (automatic selection)\")\n",
    "print(f\"‚Ä¢ Cross-validation ensures robust hyperparameter selection\")\n",
    "print(f\"‚Ä¢ Both models benefit from proper feature scaling\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9826f1e5",
   "metadata": {},
   "source": [
    "# Question 4: Multiclass Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58a4d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70c1b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "251e2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean, X_std = X_train.mean(axis=0), X_train.std(axis=0) + 1e-12\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_test  = (X_test  - X_mean) / X_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9925129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = np.clip(z, -30, 30)\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def bin_log_loss(y_true, p, w, alpha=0.0):\n",
    "    eps = 1e-12\n",
    "    loss = -np.mean(y_true * np.log(p + eps) + (1 - y_true) * np.log(1 - p + eps))\n",
    "    reg = alpha * np.sum(w**2)\n",
    "    return loss + reg\n",
    "\n",
    "def fit_binary_logistic(X, y01, lr=0.1, alpha=0.0, iters=2000, tol=1e-8):\n",
    "    n, d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    b = 0.0\n",
    "    prev = 1e18\n",
    "    for _ in range(iters):\n",
    "        z = X @ w + b\n",
    "        p = sigmoid(z)\n",
    "        grad_w = (X.T @ (p - y01)) / n + 2 * alpha * w\n",
    "        grad_b = np.mean(p - y01)\n",
    "        w -= lr * grad_w\n",
    "        b -= lr * grad_b\n",
    "        cur = bin_log_loss(y01, p, w, alpha)\n",
    "        if abs(prev - cur) < tol:\n",
    "            break\n",
    "        prev = cur\n",
    "    return w, b\n",
    "\n",
    "def predict_proba_binary(X, w, b):\n",
    "    return sigmoid(X @ w + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaf7e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = len(np.unique(y_train))\n",
    "weights, biases = [], []\n",
    "lr = 0.1\n",
    "alpha = 0.0\n",
    "iters = 4000\n",
    "\n",
    "for k in range(K):\n",
    "    y01 = (y_train == k).astype(float)\n",
    "    w_k, b_k = fit_binary_logistic(X_train, y01, lr=lr, alpha=alpha, iters=iters)\n",
    "    weights.append(w_k)\n",
    "    biases.append(b_k)\n",
    "weights, biases = np.vstack(weights), np.array(biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1c6ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.column_stack([\n",
    "    predict_proba_binary(X_test, weights[k], biases[k]) for k in range(K)\n",
    "])\n",
    "y_pred = probs.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "234725bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8684\n",
      "Confusion Matrix:\n",
      " [[11  1  0]\n",
      " [ 0 10  3]\n",
      " [ 0  1 12]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9167    0.9565        12\n",
      "           1     0.8333    0.7692    0.8000        13\n",
      "           2     0.8000    0.9231    0.8571        13\n",
      "\n",
      "    accuracy                         0.8684        38\n",
      "   macro avg     0.8778    0.8697    0.8712        38\n",
      "weighted avg     0.8746    0.8684    0.8690        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
