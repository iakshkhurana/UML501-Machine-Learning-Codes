{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iakshkhurana/UML501-Machine-Learning-Codes/blob/main/Assignment-4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kRV6PqFD0N6s"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qyq3rvpx0b7k"
      },
      "outputs": [],
      "source": [
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uNAZg0Uc1bdL"
      },
      "outputs": [],
      "source": [
        "url = \"https://books.toscrape.com/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LPgy0vr-1hDM"
      },
      "outputs": [],
      "source": [
        "response = requests.get(url)\n",
        "html_doc = response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KG7bXBpF1s37"
      },
      "outputs": [],
      "source": [
        "soup = BeautifulSoup(html_doc, 'html.parser')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uCnsaY11zJc",
        "outputId": "4ec9e0c2-18fa-48f8-b4aa-cfa032675ae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A Light in the Attic\n",
            "Tipping the Velvet\n",
            "Soumission\n",
            "Sharp Objects\n",
            "Sapiens: A Brief History of Humankind\n",
            "The Requiem Red\n",
            "The Dirty Little Secrets of Getting Your Dream Job\n",
            "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\n",
            "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\n",
            "The Black Maria\n",
            "Starving Hearts (Triangular Trade Trilogy, #1)\n",
            "Shakespeare's Sonnets\n",
            "Set Me Free\n",
            "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\n",
            "Rip it Up and Start Again\n",
            "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\n",
            "Olio\n",
            "Mesaerion: The Best Science Fiction Stories 1800-1849\n",
            "Libertarianism for Beginners\n",
            "It's Only the Himalayas\n"
          ]
        }
      ],
      "source": [
        "books = soup.find_all(\"h3\")\n",
        "for book in books:\n",
        "  print(book.a.get(\"title\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ7xOu292TEE",
        "outputId": "6970c707-e359-47ca-e547-ac03ba510df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Â£51.77\n",
            "Â£53.74\n",
            "Â£50.10\n",
            "Â£47.82\n",
            "Â£54.23\n",
            "Â£22.65\n",
            "Â£33.34\n",
            "Â£17.93\n",
            "Â£22.60\n",
            "Â£52.15\n",
            "Â£13.99\n",
            "Â£20.66\n",
            "Â£17.46\n",
            "Â£52.29\n",
            "Â£35.02\n",
            "Â£57.25\n",
            "Â£23.88\n",
            "Â£37.59\n",
            "Â£51.33\n",
            "Â£45.17\n"
          ]
        }
      ],
      "source": [
        "prices = soup.find_all(\"p\", class_=\"price_color\")\n",
        "for price in prices:\n",
        "  print(price.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT-zvvF72918",
        "outputId": "babc7f4b-05fa-43b1-95d3-f3b227683f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n",
            "In stock\n"
          ]
        }
      ],
      "source": [
        "availability = soup.find_all(\"p\", class_=\"instock availability\")\n",
        "for avail in availability:\n",
        "  print(avail.text.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npOyiy0m3Alj",
        "outputId": "f4edc7b8-b404-4031-c9ed-2d64f5edeffc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "stars = soup.find_all(\"p\",class_=\"star-rating Three\")\n",
        "for star in stars:\n",
        "  print(star.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVCvFbwS3m07"
      },
      "source": [
        "Question-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5OJxFi4F3UGL"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Movie Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>IMDB Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Rank, Movie Title, Year, IMDB Rating]\n",
              "Index: []"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.imdb.com/chart/top/\"\n",
        "r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "movies = []\n",
        "rows = soup.select(\"tbody.lister-list tr\")\n",
        "\n",
        "for i, row in enumerate(rows, start=1):\n",
        "    title = row.select_one(\".titleColumn a\").text.strip()\n",
        "    year = row.select_one(\".secondaryInfo\").text.strip(\"()\")\n",
        "    rating = row.select_one(\".imdbRating strong\").text.strip()\n",
        "    movies.append([i, title, year, rating])\n",
        "\n",
        "df = pd.DataFrame(movies, columns=[\"Rank\", \"Movie Title\", \"Year\", \"IMDB Rating\"])\n",
        "df.to_csv(\"imdb_top250.csv\", index=False)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>City</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Accra</td>\n",
              "      <td>बुध 09.23</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Addis Ababa</td>\n",
              "      <td>बुध 12.23</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adelaide</td>\n",
              "      <td>बुध 18.53</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Algiers</td>\n",
              "      <td>बुध 10.23</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Almaty</td>\n",
              "      <td>बुध 14.23</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          City Temperature Condition\n",
              "0        Accra   बुध 09.23          \n",
              "1  Addis Ababa   बुध 12.23          \n",
              "2     Adelaide   बुध 18.53          \n",
              "3      Algiers   बुध 10.23          \n",
              "4       Almaty   बुध 14.23          "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.timeanddate.com/weather/\"\n",
        "r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "cities = []\n",
        "# Find ANY table with weather data (look for \"°C\" or \"°F\" in it)\n",
        "tables = soup.find_all(\"table\")\n",
        "target_table = None\n",
        "for t in tables:\n",
        "    if \"°C\" in t.get_text() or \"°F\" in t.get_text():\n",
        "        target_table = t\n",
        "        break\n",
        "\n",
        "if target_table:\n",
        "    for row in target_table.find_all(\"tr\")[1:]:\n",
        "        cols = row.find_all(\"td\")\n",
        "        if len(cols) >= 3:\n",
        "            city = cols[0].get_text(strip=True)\n",
        "            temp = cols[1].get_text(strip=True)\n",
        "            cond = cols[2].get_text(strip=True)\n",
        "            cities.append([city, temp, cond])\n",
        "\n",
        "df = pd.DataFrame(cities, columns=[\"City\", \"Temperature\", \"Condition\"])\n",
        "df.to_csv(\"weather.csv\", index=False)\n",
        "df.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP1bHqTxicwA7q4xjV8k4K1",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
